ggplot(data = df, mapping=aes(x=group, y=rate)) +
geom_boxplot(mapping=aes(fill = group)) + geom_point()
library(fastR2)
library(tidyverse)
df <- PetStress
ggplot(data = df, mapping=aes(x=group, y=rate)) +
geom_boxplot(mapping=aes(fill = group)) + geom_point()
summary_stats <- df %>%
group_by(group) %>%
summarize(mean = mean(rate), sd = sd(rate))
ggplot(data = df, mapping=aes(x=group, y=rate)) +
geom_boxplot(mapping=aes(fill = group)) + geom_point()
View(summary_stats)
library(openintro)
install.packages("openintro")
library(openintro)
df <- ncbirths
df <- ncbirths
View(df)
df %>% group_by(habit) %>% summarize(mean(weight), var(weight))
?qt
qt(0.025, df=997)
qt(0.975, df=997)
mosaic::t.test(weight~habit, data = ncbirths, var.equal=T)
mosaic::t.test(weight~habit, data = ncbirths, var.equal=F)
pt(2.1678, df=997)
pt(-2.2034, df=997) * 2
gamma(4)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
install.packages("GoFKernel")
library(GoFKernel)
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
}
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
}
c(1.22, 3.4)
c(-1,1)*1.23
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
?rexp
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
rlang::last_error()
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
q1 = u_quantile(alpha/2, n=n)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf, n=n)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
#u_quantile <- inverse(u_cdf, lower=0, upper=Inf, n=n)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
View(u_cdf)
u_cdf(u=2, n=12)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_pdf <- function(u, n) {
f = (1/gamma(n)) * u^(n-1) * exp(-u)
}
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = u_pdf)
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
?mosaic::t.test
df <- PetStress
ggplot(data = df, mapping=aes(x=group, y=rate)) +
geom_boxplot(mapping=aes(fill = group)) + geom_point()
summary_stats <- df %>%
group_by(group) %>%
summarize(mean = mean(rate), sd = sd(rate))
View(df)
mosaic::t.test(group~rate, data = df, var.equal=F)
CandF <- df %>%
filter(group == "C" || group == "F")
View(CandF)
View(df)
df
type(df[group])
str(df)
CandF <- df %>%
filter(group == "C" | group == "F")
CandP <- df %>%
filter(group = "C" | group = "P")
CandP <- df %>%
filter(group = "C" | group = "P")
CandP <- df %>%
filter(group == "C" | group == "P")
PandF <- df %>%
filter(group == "P" | group == "F")
View(CandP)
mosaic::t.test(group~rate, data = CandF, var.equal=F)
View(CandF)
df <- ncbirths
View(df)
df <- PetStress
mosaic::t.test(rate~group, data = CandF, var.equal=F)
mosaic::t.test(rate~group, data = CandP, var.equal=F)
mosaic::t.test(rate~group, data = PandF, var.equal=F)
df <- Endurance
View(df)
View(df)
df <- df %>%
mutate(diff = vitamin - placebo)
View(df)
t.test(~diff, data = df, mu=0, alternative="two.sided")
df <- df %>%
mutate(log_diff = log(vitamin) - log(placebo))
View(df)
t.test(~log_diff, data=df, mu=0, alternative="two.sided")
df <- df %>%
mutate(quotient = vitamin / placebo)
View(df)
t.test(~quotient, data=df, mu=1, alternative="two.sided")
t.test(~quotient, data=df, mu=0, alternative="two.sided")
t.test(~quotient, data=df, mu=1, alternative="two.sided")
View(df)
df <- df %>%
mutate(reciprocal_diff = (1/vitamin) - (1/placebo))
t.test(~reciprocal_diff, data=df, mu=1, alternative="two.sided")
t.test(~reciprocal_diff, data=df, mu=0, alternative="two.sided")
df <- df %>%
mutate(improved = vitamin > placebo)
binom.test(~improved, alternative="two.sided", p=0.5, data = df)
t.test(~diff, data = df, mu=0, alternative="two.sided")
t.test(~quotient, data=df, mu=1, alternative="two.sided")
t.test(~reciprocal_diff, data=df, mu=0, alternative="two.sided")
t.test(~quotient, data=df, mu=0, alternative="two.sided")
t.test(~quotient, data=df, mu=1, alternative="two.sided")
t.test(~diff, data = df, mu=0, alternative="two.sided")
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = (1/gamma(n)) * u^(n-1) * exp(-u) )
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
u_pdf <- function(u, n) {
f = (1/gamma(n)) * u^(n-1) * exp(-u)
}
u_cdf <- function(u, n) {
integrate(lower=0, upper=u,
f = u_pdf, args=list(n=n, u = u))
}
u_quantile <- inverse(u_cdf, lower=0, upper=Inf)
q1 = u_quantile(alpha/2)
q2 = u_quantile(1 - (alpha/2))
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
q1 = qgamma(alpha/2, shape=n, scale=1)
q2 = qgamma(1-(alpha/2), shape = n, scale = 1)
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
?CIsim
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
expci <- function(x, conf.level=0.95) {
n = length(x)
alpha = 1-conf.level
s = sum(x)
q1 = qgamma(alpha/2, shape=n, scale=1)
q2 = qgamma(1-(alpha/2), shape = n, scale = 1)
lower <- s/q2
upper <- s/q1
interval = c(lower, upper)
return(list(conf.int=interval, estiamte=(s/n)))
}
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
CIsim(n=5, samples=5000, rdist=rexp,
args=list(rate=0.1), estimand = 10, method=expci)
library(tidyverse)
x<-c(0.64,0.92,0.73,0.96,0.98,0.33,0.80,0.96,0.81,0.76,0.98,0.75,
0.87,0.82,0.44,0.96,0.61,0.32,0.67,0.98,0.96,0.88,0.85,1.00,
0.86,0.88,0.80,0.83,0.64,0.5)
length(x)
n <- length(x)
lik_ratio <- 1 / (((-n/sum(log(x)))^n) * prod(x^(-1 - (n / sum(ln(x))))))
lik_ratio <- 1 / (((-n/sum(log(x)))^n) * prod(x^(-1 - (n / sum(log(x))))))
theta_opt <- -1 - (n / sum(log(x)))
likratio <- function(theta, x) {
like_null <- product((theta + 1) * (x ^ theta)),
like_alt <- product(theta_opt + 1) * (x ^ theta_opt)
}
likratio <- function(theta, x) {
like_null <- product((theta + 1) * (x ^ theta)),
like_alt <- product(theta_opt + 1) * (x ^ theta_opt)
}
likratio <- function(theta, x) {
like_null <- product((theta + 1) * (x ^ theta)),
like_alt <- product(theta_opt + 1) * (x ^ theta_opt)
}
likratio <- function(theta, x) {
like_null <- prod((theta + 1) * (x ^ theta)),
like_alt <- prod(theta_opt + 1) * (x ^ theta_opt)
}
likratio <- function(theta, x) {
like_null <- prod((theta + 1) * (x ^ theta)),
like_alt <- prod((theta_opt + 1) * (x ^ theta_opt))
}
likratio <- function(theta, x) {
like_null <- prod((theta + 1) * (x^theta)),
like_alt <- prod((theta_opt + 1) * (x^theta_opt))
}
likratio <- function(theta, x, theta_opt) {
like_null <- prod((theta + 1) * (x^theta)),
like_alt <- prod((theta_opt + 1) * (x^theta_opt))
}
likratio <- function(theta, x, theta_opt, n) {
like_null <- prod((theta + 1) * (x^theta)),
like_alt <- prod((theta_opt + 1) * (x^theta_opt))
}
likratio <- function(theta, x, theta_opt, n) {
like_null <- prod((theta + 1) * (x^theta))
like_alt <- prod((theta_opt + 1) * (x^theta_opt))
like_null / like_alt
}
df <- tibble(
theta = seq(-0.99, 5, 0.01),
lambda = likratio(theta, x, theta_opt, n)
)
ggplot(df, mapping = aes(x = theta, y = lambda)) +
geom_line()
df <- tibble(
theta = seq(-0.99, 1, 0.01),
lambda = likratio(theta, x, theta_opt, n)
)
ggplot(df, mapping = aes(x = theta, y = lambda)) +
geom_line()
View(df)
likratio <- function(theta, x, theta_opt, n) {
like_null <- prod((theta + 1) * (x^theta))
like_alt <- prod((theta_opt + 1) * (x^theta_opt))
(like_null / like_alt)
}
df <- tibble(
theta = seq(-0.99, 1, 0.01),
lambda = likratio(theta, x, theta_opt, n)
)
ggplot(df, mapping = aes(x = theta, y = lambda)) +
geom_line()
library(maxLik)
library(fast2)
library(fastR2)
loglik.fun <- function(theta, x) {
(len(x) * log(theta + 1)) + (theta * sum(log(x)))
}
maxLik2(loglik.fun, start = 1, x = x)
loglik.fun <- function(theta, x) {
(length(x) * log(theta + 1)) + (theta * sum(log(x)))
}
maxLik2(loglik.fun, start = 1, x = x)
df <- tibble(
theta = seq(-0.99, 5, 0.01),
lambda = likratio(theta, x, theta_opt, n)
)
ggplot(df, mapping = aes(x = theta, y = lambda)) +
geom_line()
prod(x^2)
prod(x^0)
likratio(1, x, theta_opt, n)
likratio(0, x, theta_opt, n)
ml <- maxLik2(loglik.fun, start = 1, x = x)
plot(ml)
-2 * log(lik_ratio)
1 - pchisq(32.75024, 1)
(theta_opt + 1)^30
((theta_opt + 1)^30) * prod(x^theta_opt)
(((theta_opt + 1)^30) * prod(x^theta_opt)) ^ -1
lik_ratio <- 1 / (((-n/sum(log(x)))^n) * prod(x^(-1 - (n / sum(log(x))))))
library(tidyverse)
x<-c(0.64,0.92,0.73,0.96,0.98,0.33,0.80,0.96,0.81,0.76,0.98,0.75,
0.87,0.82,0.44,0.96,0.61,0.32,0.67,0.98,0.96,0.88,0.85,1.00,
0.86,0.88,0.80,0.83,0.64,0.5)
n <- length(x)
# Calculating our test statistic
lik_ratio <- 1 / (((-n/sum(log(x)))^n) * prod(x^(-1 - (n / sum(log(x))))))
# Calculating our p value
p_val <- 1 - pchisq(q = 32.75024, df = 1)
# Plotting the log likelihood function vs the second order taylor polynomial
ml <- maxLik2(loglik.fun, start = 1, x = x)
library(tidyverse)
x<-c(0.64,0.92,0.73,0.96,0.98,0.33,0.80,0.96,0.81,0.76,0.98,0.75,
0.87,0.82,0.44,0.96,0.61,0.32,0.67,0.98,0.96,0.88,0.85,1.00,
0.86,0.88,0.80,0.83,0.64,0.5)
n <- length(x)
# Calculating our test statistic
lik_ratio <- 1 / (((-n/sum(log(x)))^n) * prod(x^(-1 - (n / sum(log(x))))))
# Calculating our p value
p_val <- 1 - pchisq(q = 32.75024, df = 1)
# Plotting the log likelihood function vs the second order taylor polynomial
loglik.fun <- function(theta, x) {
(length(x) * log(theta + 1)) + (theta * sum(log(x)))
}
ml <- maxLik2(loglik.fun, start = 1, x = x)
plot(ml)
setwd("C:/Users/Admin/Desktop/CSE 412/transportation-accessibility/data")
blockgroups <- read.csv("block_broup_data.csv")
blockgroups <- read.csv("block_group_data.csv")
meansoftrans <- read.csv("means_of_transportation.csv")
meansoftranstravtime <- read.csv("means_of_transportation_by_travel_time.csv")
View(meansoftrans)
View(meansoftranstravtime)
meansoftrans <- read.csv("means_of_transportation_by_travel_time.csv")
head(meansoftrans)
View(meansoftranstravtime)
View(blockgroups)
race <- read.csv("race.csv")
View(race)
View(meansoftranstravtime)
View(race)
install.packages("treemap")
install.packages("treemap")
View(race)
race_tree_data -> race %>%
summarize(sum(estimate_total_white_alone))
race_tree_data <- race %>%
summarize(sum(estimate_total_white_alone))
View(race_tree_data)
View(race)
race_tree_data <- race %>%
summarize(sum(estimate_total_white_alone), sum(estimate_total_black_or_african_american_alone),
sum(estimate_total_asian_alone), sum(estimate_total_american_indian_and_alaska_native_alone),
sum(estimate_total_native_hawaiian_and_other_pacific_islander_alone), sum(estimate_total_some_other_race_alone),
multiple_races = (sum(estimate_total_two_or_more_races) + sum(estimate_total_two_or_more_races_two_races_including_some_other_race) +
sum(estimate_total_two_or_more_races_two_races_excluding_some_other_race_and_three_or_more_races)))
View(race_tree_data)
View(race)
race_tree_data <- race %>%
summarize(sum(estimate_total_white_alone), sum(estimate_total_black_or_african_american_alone),
sum(estimate_total_asian_alone), sum(estimate_total_american_indian_and_alaska_native_alone),
sum(estimate_total_native_hawaiian_and_other_pacific_islander_alone), sum(estimate_total_some_other_race_alone),
multiple_races = sum(estimate_total_two_or_more_races))
View(race_tree_data)
group <- c("White", "Black", "Asian", "Native American", "Pacific Islander", "Other", "Multiple Races")
race_tree_data[1,]
test <- race_tree_data[1,]
View(test)
test <- as.numeric(race_tree_data)
values <- as.numeric(race_tree_data)
data <- data.frame(group, value)
data <- data.frame(group, values)
treemap(data, index = "group", vSize = "value", type = "index")
library(treemap)
treemap(data, index = "group", vSize = "value", type = "index")
library(treemap)
treemap(data, index = "group", vSize = "value", type = "index")
# library
library(treemap)
# Create data
group <- c("group-1","group-2","group-3")
value <- c(13,5,22)
data <- data.frame(group,value)
# treemap
treemap(data,
index="group",
vSize="value",
type="index"
)
race_tree_data <- race %>%
summarize(sum(estimate_total_white_alone), sum(estimate_total_black_or_african_american_alone),
sum(estimate_total_asian_alone), sum(estimate_total_american_indian_and_alaska_native_alone),
sum(estimate_total_native_hawaiian_and_other_pacific_islander_alone), sum(estimate_total_some_other_race_alone),
multiple_races = sum(estimate_total_two_or_more_races))
group <- c("White", "Black", "Asian", "Native American", "Pacific Islander", "Other", "Multiple Races")
values <- as.numeric(race_tree_data)
data <- data.frame(group, values)
treegraph(data, index = "group", vSize = "value", type = "index")
install.packages("treemap")
treemap(data, index = "group", vSize = "value", type = "index")
?treemap
??treemap
treemap::treemap(data, index = "group", vSize = "value", type = "index")
treemap(data, index = "group", vSize = "value", type = "index")
q()
